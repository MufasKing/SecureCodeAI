# SecureCodeAI

## Universit√† Degli Studi di Napoli Federico II - Thesis Project

Code security is of significant importance in the context of software development, as it serves to mitigate the potential for vulnerabilities that could otherwise lead to system crashes or data breaches. While Artificial Intelligence (AI) has the capacity to expedite the development process, it is also capable of introducing errors unless subjected to rigorous oversight. In order to mitigate risks, it is imperative that corporations automate the detection of vulnerabilities and implement robust security controls, particularly when utilising AI within the coding process.
In this study, we train a Large Language Model (LLM) to generate secure code. To this end, the LLMSecEval dataset is employed. It comprising prompts designed to unleash vulnerabilities associated with the twenty-five principal CWEs (Common Weakness Enumeration) categories identified by MITRE, along with Python-based programs designed to prevent such vulnerabilities. Each prompt is analyzed with Secure Code Studio, a tool that not only generates the code but also offers a set of Best Practices for secure programming. However, the initial number of examples provided was inadequate to achieve the desired outcome. To work around this limitation, the prompts and related Best Practices are provided as input to ChatGPT and Copilot, resulting in three distinct code examples for each prompt. The aforementioned examples, in conjunction with the prompts and Best Practices, have been organized into a structured dataset in the form of a catalog. The Catalog also includes an indication of the CWE associated with each prompt. We elected to denominate this construction technique Best Practice-Driven Secure Code Refinement (BPSecRef). The resulting Catalog is then employed for the fine-tuning of Gemma which, following training, generates code devoid of the vulnerabilities associated with the provided prompts. Ultimately, a comprehensive security analysis is conducted on the Catalog, with validations conducted on two distinct fronts: the construction technique, as applied to the C++ language, and the general validity, tested with the Java language. The results of these analyses demonstrate that the catalog is an effective tool for mitigating vulnerabilities in AI-generated code, and its utility is not limited to a specific programming language. The catalog thus constructed and validated is called the "Secure Code Catalog".